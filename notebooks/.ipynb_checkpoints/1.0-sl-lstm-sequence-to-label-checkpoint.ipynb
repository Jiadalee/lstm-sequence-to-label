{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raw data filenames.\n",
    "\n",
    "rawdata_file1 = '../data/raw/datatraining.txt'\n",
    "rawdata_file2 = '../data/raw/datatest.txt'\n",
    "outdata_file = '../data/interim/occupancy_dl-models.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data, parsing the date column into datetime64 format, and combine\n",
    "# train and test set into a single dataframe.\n",
    "\n",
    "parse_dates = ['date']\n",
    "index_col = 'ObservationID'\n",
    "\n",
    "occupancy_df = pd.read_csv(rawdata_file1, parse_dates=parse_dates, index_col=index_col)\n",
    "occupancy2_df = pd.read_csv(rawdata_file2, parse_dates=parse_dates, index_col=index_col)\n",
    "\n",
    "occupancy_df = pd.concat([occupancy_df, occupancy2_df], ignore_index=True)\n",
    "occupancy_df.index.names = [index_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimof_input:  4\n",
      "dimof_output:  2\n"
     ]
    }
   ],
   "source": [
    "# Extract data from pandas dataframes and rescale.\n",
    "\n",
    "Y = np.array(occupancy_df['Occupancy'].values)\n",
    "X = np.array(occupancy_df[['CO2', 'Light', 'Temperature', 'Humidity']])\n",
    "\n",
    "# Get dimensions of input and output\n",
    "dimof_output = int(np.max(Y) + 1)\n",
    "dimof_input = X.shape[1]\n",
    "print('dimof_input: ', dimof_input)\n",
    "print('dimof_output: ', dimof_output)\n",
    "\n",
    "# Scale/whiten the X data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Set y as categorical data\n",
    "Y = np_utils.to_categorical(Y, dimof_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training data shape =  (8072, 45, 4)\n",
      "Y training data shape (8072, 2)\n",
      "X test data shape =  (2690, 45, 4)\n",
      "Y test data shape (2690, 2)\n"
     ]
    }
   ],
   "source": [
    "# Set up a 'look back' dataset for sequence to label prediction with Keras.\n",
    "\n",
    "# The LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features].\n",
    "\n",
    "# create_dataset is adapted from\n",
    "# http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \"\"\"Convert an array of X, Y values into a dataset matrix for and LSTM\"\"\"\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back - 1):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def train_test_split_sequential(X, Y, **options):\n",
    "    \"\"\"Splits data into train test sets, based on a fraction test_size samples\n",
    "    from the end of the timeseries\"\"\"\n",
    "    \n",
    "    test_size = options.pop('test_size', None)\n",
    "    if test_size is None:\n",
    "        test_size = 0.25\n",
    "        \n",
    "    n_sample = len(Y)\n",
    "    n_test = int(n_sample * test_size)\n",
    "        \n",
    "    X_train = X[:-n_test]\n",
    "    Y_train = Y[:-n_test]\n",
    "\n",
    "    X_test = X[-n_test:]\n",
    "    Y_test = Y[-n_test:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Predictions will be based on look_back minutes of data:\n",
    "look_back = 45\n",
    "X_all, Y_all = create_dataset(X, Y, look_back=look_back)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split_sequential(X_all, Y_all, test_size=0.25)\n",
    "\n",
    "print('X training data shape = ', X_train.shape)\n",
    "print('Y training data shape', Y_train.shape)\n",
    "\n",
    "print('X test data shape = ', X_test.shape)\n",
    "print('Y test data shape', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the LSTM network.\n",
    "\n",
    "batch_size = 32\n",
    "dropout = 0.4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(output_dim=dimof_output, batch_input_shape=[batch_size, look_back, dimof_input]))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(dimof_output, init='uniform', activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model for num_epoch epochs, with an early stopping criterion.\n",
    "\n",
    "num_epoch = 32\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[earlyStopping],\n",
    "    nb_epoch=num_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot history for training and validation loss.\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show model predictions against input occupancy labels, and input data timestreams\n",
    "\n",
    "Y_predict = model.predict_classes(X_all, verbose=True)\n",
    "series = np.hstack((np.zeros(look_back + 1, dtype=int), Y_predict))\n",
    "occupancy_df['LSTM'] = pd.Series(series, index=occupancy_df.index)\n",
    "\n",
    "occupancy_df['Occupancy'].plot(figsize=[20, 10], legend=True)\n",
    "occupancy_df['LSTM'].apply(lambda x: x - 1.1).plot(legend=True)\n",
    "occupancy_df['CO2'].apply(lambda x: (x - 420.)/400. + 1).plot(legend=True)\n",
    "occupancy_df['Light'].apply(lambda x: x/450. + 2).plot(legend=True)\n",
    "occupancy_df['Temperature'].apply(lambda x: x - 15).plot(legend=True)\n",
    "occupancy_df['Humidity'].apply(lambda x: x / 5. ).plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Serialize model to YAML.\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open('../models/model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# Serialize weights to HDF5\n",
    "\n",
    "model.save_weights('../models/model.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write predictions to disk\n",
    "\n",
    "occupancy_df.to_csv(outdata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
